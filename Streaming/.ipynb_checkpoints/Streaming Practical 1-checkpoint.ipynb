{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcXGl7FCaYIP"
   },
   "source": [
    "## Streaming Practical 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqwyRqR-aZlm"
   },
   "source": [
    "### Streaming from TCP Socket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RO3rBNyham7p"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TCP = (spark.readStream.format('socket')\n",
    "         .option('host','localhost')\n",
    "         .option('port',9090)\n",
    "         .load()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3K1aRW5akJe"
   },
   "source": [
    "### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "T0Ka-uF-akre",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TCP.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCP.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMeDLWdjarSP"
   },
   "source": [
    "### After processing, you can write the DataFrame to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "df_words=TCP.select(explode(split(TCP.value,' ')).alias('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=df_words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 01:40:31 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-1f815e21-9e0c-4828-a3ee-ffdb293b7a8f. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "| Trying|    2|\n",
      "|     HW|    2|\n",
      "|    you|    1|\n",
      "|example|    2|\n",
      "|  HelLo|    2|\n",
      "|     Hi|    1|\n",
      "|  doing|    1|\n",
      "|    How|    1|\n",
      "|    TCP|    2|\n",
      "|    are|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 01:42:51 WARN TextSocketMicroBatchStream: Stream closed by localhost:9090\n"
     ]
    }
   ],
   "source": [
    "count.writeStream\\\n",
    "      .format(\"console\")\\\n",
    "      .outputMode(\"complete\")\\\n",
    "      .start()\\\n",
    "      .awaitTermination(120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXv7fZGSO7cD"
   },
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2k9D8n-JS_P"
   },
   "source": [
    "letâ€™s create a streaming DataFrame that represents text data received from a server listening on localhost:9999, and transform the DataFrame to calculate word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxtuiijIJXea"
   },
   "source": [
    "### Create DataFrame representing the stream of input lines from connection to localhost:9999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 01:43:54 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "df = (spark.readStream.format('socket')\n",
    "         .option('host','localhost')\n",
    "         .option('port',9999)\n",
    "         .load()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfP3TwpWJdkY"
   },
   "source": [
    "### Split the lines into words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "j_QcRC98asO-"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "words = df.select(explode(split(df.value,' ')).alias('word'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGS9HgfzJowv"
   },
   "source": [
    "### Generate running word count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "b2FRcEbSJnW_"
   },
   "outputs": [],
   "source": [
    "wordCounts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asH2FPJOJ1iK"
   },
   "source": [
    "### Start running the query that prints the running counts to the console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WI2791DnJ3r0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 01:45:23 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 1000 milliseconds, but spent 63810 milliseconds\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|  name|    2|\n",
      "|asking|    2|\n",
      "|   you|    6|\n",
      "|thanks|    2|\n",
      "|   for|    2|\n",
      "|    Hi|    2|\n",
      "|    is|    4|\n",
      "|   All|    2|\n",
      "|  Fine|    2|\n",
      "| doing|    2|\n",
      "|   How|    2|\n",
      "|    my|    2|\n",
      "| thank|    2|\n",
      "|  what|    2|\n",
      "|   are|    2|\n",
      "|  well|    2|\n",
      "| Reham|    2|\n",
      "| about|    2|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 01:46:15 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 1000 milliseconds, but spent 52108 milliseconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointDir = \"chkpont\"\n",
    "streamingQuery = (wordCounts.writeStream\n",
    "                  .format(\"console\")\n",
    "                  .outputMode(\"complete\")\n",
    "                  .trigger(processingTime=\"1 second\")\n",
    "                  .option(\"checkpointLocation\", checkpointDir)\n",
    "                  .start())\n",
    "streamingQuery.awaitTermination(120)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "H_W_Session_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
