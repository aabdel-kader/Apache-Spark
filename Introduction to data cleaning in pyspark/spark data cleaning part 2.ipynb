{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deaf6f14",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. cashing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03de7ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import findspark\\n\\nfindspark.init()\";\n",
       "                var nbb_formatted_code = \"import findspark\\n\\nfindspark.init()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a9856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001F666C58580>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import *\\nfrom pyspark.sql.types import *\\n\\nspark = SparkSession.builder.getOrCreate()\\nprint(spark)\";\n",
       "                var nbb_formatted_code = \"from pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import *\\nfrom pyspark.sql.types import *\\n\\nspark = SparkSession.builder.getOrCreate()\\nprint(spark)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674f9d0",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "You'll be working with a new dataset consisting of airline departure information. It may have repetitive data and will need to be de-duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8deaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting 157198 rows took 1.310269 seconds\n",
      "Counting 157198 rows again took 1.774900 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# The effect of the code in this cell is also not obvious beacurse I'm working locally !\\nimport time\\n\\ndepartures_df = spark.read.csv(\\\"datasets/AA_DFW_2014_Departures_Short.csv\\\" , header=True , inferSchema=True)\\n\\nstart_time = time.time()\\n\\n# Add caching to the unique rows in departures_df\\ndepartures_df = departures_df.distinct().cache()\\n\\n# Count the unique rows in departures_df, noting how long the operation takes\\nprint(\\\"Counting %d rows took %f seconds\\\" % (departures_df.count(), time.time() - start_time))\\n\\n# Count the rows again, noting the variance in time of a cached DataFrame\\nstart_time = time.time()\\nprint(\\\"Counting %d rows again took %f seconds\\\" % (departures_df.count(), time.time() - start_time))\";\n",
       "                var nbb_formatted_code = \"# The effect of the code in this cell is also not obvious beacurse I'm working locally !\\nimport time\\n\\ndepartures_df = spark.read.csv(\\n    \\\"datasets/AA_DFW_2014_Departures_Short.csv\\\", header=True, inferSchema=True\\n)\\n\\nstart_time = time.time()\\n\\n# Add caching to the unique rows in departures_df\\ndepartures_df = departures_df.distinct().cache()\\n\\n# Count the unique rows in departures_df, noting how long the operation takes\\nprint(\\n    \\\"Counting %d rows took %f seconds\\\"\\n    % (departures_df.count(), time.time() - start_time)\\n)\\n\\n# Count the rows again, noting the variance in time of a cached DataFrame\\nstart_time = time.time()\\nprint(\\n    \\\"Counting %d rows again took %f seconds\\\"\\n    % (departures_df.count(), time.time() - start_time)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The effect of the code in this cell is also not obvious beacurse I'm working locally !\n",
    "import time\n",
    "\n",
    "departures_df = spark.read.csv(\"datasets/AA_DFW_2015_Departures_Short.csv\" , header=True , inferSchema=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Add caching to the unique rows in departures_df\n",
    "departures_df = departures_df.distinct().cache()\n",
    "\n",
    "# Count the unique rows in departures_df, noting how long the operation takes\n",
    "print(\"Counting %d rows took %f seconds\" % (departures_df.count(), time.time() - start_time))\n",
    "\n",
    "# Count the rows again, noting the variance in time of a cached DataFrame\n",
    "start_time = time.time()\n",
    "print(\"Counting %d rows again took %f seconds\" % (departures_df.count(), time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8779863",
   "metadata": {},
   "source": [
    "### Removing data form cache using unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080f29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is departures_df cached?: True\n",
      "Removing departures_df from cache\n",
      "Is departures_df cached?: False\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Determine if departures_df is in the cache\\nprint(\\\"Is departures_df cached?: %s\\\" % departures_df.is_cached)\\nprint(\\\"Removing departures_df from cache\\\")\\n\\n# Remove departures_df from the cache\\ndepartures_df.unpersist()\\n\\n# Check the cache status again\\nprint(\\\"Is departures_df cached?: %s\\\" % departures_df.is_cached)\";\n",
       "                var nbb_formatted_code = \"# Determine if departures_df is in the cache\\nprint(\\\"Is departures_df cached?: %s\\\" % departures_df.is_cached)\\nprint(\\\"Removing departures_df from cache\\\")\\n\\n# Remove departures_df from the cache\\ndepartures_df.unpersist()\\n\\n# Check the cache status again\\nprint(\\\"Is departures_df cached?: %s\\\" % departures_df.is_cached)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine if departures_df is in the cache\n",
    "print(\"Is departures_df cached?: %s\" % departures_df.is_cached)\n",
    "print(\"Removing departures_df from cache\")\n",
    "\n",
    "# Remove departures_df from the cache\n",
    "departures_df.unpersist()\n",
    "\n",
    "# Check the cache status again\n",
    "print(\"Is departures_df cached?: %s\" % departures_df.is_cached)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922107ed",
   "metadata": {},
   "source": [
    "### Quick pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5889d2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Remove any duration of 0\\ndepartures_df = departures_df.filter(departures_df[3] > 0)\\n\\n# Add an ID column\\ndepartures_df = departures_df.withColumn('id', monotonically_increasing_id())\\n\\n# Write the file out to JSON format\\ndepartures_df.write.json('output.json', mode='overwrite')\";\n",
       "                var nbb_formatted_code = \"# Remove any duration of 0\\ndepartures_df = departures_df.filter(departures_df[3] > 0)\\n\\n# Add an ID column\\ndepartures_df = departures_df.withColumn(\\\"id\\\", monotonically_increasing_id())\\n\\n# Write the file out to JSON format\\ndepartures_df.write.json(\\\"output.json\\\", mode=\\\"overwrite\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove any duration of 0\n",
    "departures_df = departures_df.filter(departures_df[3] > 0)\n",
    "\n",
    "# Add an ID column\n",
    "departures_df = departures_df.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "# Write the file out to JSON format\n",
    "departures_df.write.json('output.json', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300c32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
