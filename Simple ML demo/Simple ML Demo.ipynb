{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIwZsU0haNkj"
   },
   "source": [
    "## Simple ML task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45wCuSvgajao"
   },
   "source": [
    "### Build SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JwcbnqiymCE3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a74d4b23d03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJLc1PY1i-Np"
   },
   "source": [
    "You've been flown to their headquarters in Ulsan, South Korea, to assist them in accurately estimating the number of crew members a ship will need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PEoknoejL4r"
   },
   "source": [
    "They're currently building new ships for certain customers, and they'd like you to create a model and utilize it to estimate how many crew members the ships will require.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70slYH-tjR81"
   },
   "source": [
    "Metadata:\n",
    "1. Measurements of ship size \n",
    "2. capacity \n",
    "3. crew \n",
    "4. age for 158 cruise ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZzrhGnHkRCU"
   },
   "source": [
    "It is saved in a csv file for you called \"ITI_data.csv\". our task is to develop a regression model that will assist in predicting the number of crew members required for future ships. The client also indicated that they have found that particular cruise lines will differ in acceptable crew counts, thus this is most likely an important factor to consider when conducting your investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "A9CZzWWqZnOC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"ITI_data.csv\" , header=True , inferSchema=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF , testDF = data.randomSplit([0.8,0.2] , seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QTNLhZSlf9_"
   },
   "source": [
    "### OneHotEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "-ZZxxxKLZnOF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_col = [c for (c,d) in trainDF.dtypes]\n",
    "string_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_Ind',\n",
       " 'Cruise_line_Ind',\n",
       " 'Age_Ind',\n",
       " 'Tonnage_Ind',\n",
       " 'passengers_Ind',\n",
       " 'length_Ind',\n",
       " 'cabins_Ind',\n",
       " 'passenger_density_Ind',\n",
       " 'crew_Ind']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output column names for StringIndexer\n",
    "strInd_col = [c+\"_Ind\" for c in string_col]\n",
    "strInd_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_OHE',\n",
       " 'Cruise_line_OHE',\n",
       " 'Age_OHE',\n",
       " 'Tonnage_OHE',\n",
       " 'passengers_OHE',\n",
       " 'length_OHE',\n",
       " 'cabins_OHE',\n",
       " 'passenger_density_OHE',\n",
       " 'crew_OHE']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output columns for OneHotEncoder\n",
    "\n",
    "OHE_col = [c+\"_OHE\" for c in string_col]\n",
    "OHE_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Tonnage', 'passengers', 'length', 'cabins', 'passenger_density']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting numeric columns to be merged with OHE columns\n",
    "numeric_cols = [c for (c,d) in trainDF.dtypes if ((d=='double' or d=='int') and (c != 'crew'))]\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name_OHE',\n",
       " 'Cruise_line_OHE',\n",
       " 'Age_OHE',\n",
       " 'Tonnage_OHE',\n",
       " 'passengers_OHE',\n",
       " 'length_OHE',\n",
       " 'cabins_OHE',\n",
       " 'passenger_density_OHE',\n",
       " 'crew_OHE',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all features together and Instantiate VectorAssembler\n",
    "all_columns = OHE_col + numeric_cols\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer , OneHotEncoder , VectorAssembler\n",
    "#Instantiate StringIndexer\n",
    "strInd = StringIndexer(inputCols=string_col , outputCols=strInd_col , handleInvalid='keep')\n",
    "\n",
    "#Instantiate OneHotEncoding\n",
    "OHEncoder = OneHotEncoder(inputCols=strInd_col , outputCols=OHE_col)\n",
    "\n",
    "#Instantiate VectorAssembler\n",
    "vecAssem = VectorAssembler(inputCols=all_columns , outputCol='features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rbf56f6AmUUl"
   },
   "source": [
    "### Create a Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "nvqnqTkunkNx"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr_multi = LinearRegression(featuresCol='features' , labelCol='crew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVdxQTcSC6Cz"
   },
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "UqM9HxkNIHwE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pip = Pipeline(stages=[strInd , OHEncoder , vecAssem , lr_multi] )\n",
    "pip_model = pip.fit(trainDF)\n",
    "\n",
    "#transform train data\n",
    "train_transformed = pip_model.transform(trainDF)\n",
    "train_pred = train_transformed.select(\"crew\" , \"prediction\")\n",
    "\n",
    "#transform test data\n",
    "test_transformed = pip_model.transform(testDF)\n",
    "test_pred = test_transformed.select(\"crew\" , \"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|crew|        prediction|\n",
      "+----+------------------+\n",
      "| 6.0| 7.163955294028179|\n",
      "| 5.2| 6.364820511097811|\n",
      "| 8.5| 8.560809743834433|\n",
      "|6.17| 6.916979653836525|\n",
      "|12.0|10.602570456632998|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEbfwhqeHOCc"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.0\n",
      "RMSE is 0.9\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(predictionCol='prediction',\n",
    "                                         labelCol='crew',\n",
    "                                         metricName='mae')\n",
    "rmse = regressionEvaluator.evaluate(train_pred)\n",
    "print(\"RMSE is {:.1f}\".format(rmse))\n",
    "\n",
    "rmse = regressionEvaluator.evaluate(test_pred)\n",
    "print(\"RMSE is {:.1f}\".format(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.8840935158691435\n"
     ]
    }
   ],
   "source": [
    "r2 = RegressionEvaluator(predictionCol='prediction',\n",
    "                                         labelCol='crew',\n",
    "                                         metricName='r2').evaluate(test_pred)\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SluXM6j-Gt9B"
   },
   "source": [
    "By Eng. Mostafa Nabieh \n",
    "If you have questions, please feel free to ask.\n",
    "\n",
    "My Email : nabieh.mostafa@yahoo.com\n",
    "\n",
    "My Whatsapp : +201015197566"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session 2 H.W.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
